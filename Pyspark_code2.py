# -*- coding: utf-8 -*-
"""Welcome To Colaboratory

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

!pip install pyspark

from pyspark.sql import SparkSession
from pyspark import SparkContext
from pyspark.sql.functions import *
from pyspark.sql import *
from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType
spark = SparkSession.builder.appName('Practice').getOrCreate()

df1 = spark.read.csv("/content/olist_products_dataset.csv",inferSchema=True, header=True)

df1.printSchema()

df2 = spark.read.csv("/content/olist_order_items_dataset.csv",inferSchema=True, header=True)

df2.createOrReplaceTempView("OrderItems")

df2.show()

df5=spark.sql("SELECT product_id, COUNT(*) as product_count FROM OrderItems GROUP BY product_id")

df6=df1.join(df5, df1['product_id'] == df5['product_id'], how='inner').select(col('product_category_name'),
                                                                              col('product_count'))
df7=df6.orderBy(desc("product_count"))
df7.show(10)

df21 = spark.read.csv("/content/olist_order_payments_dataset.csv",inferSchema=True, header=True)
df22 = spark.read.csv("/content/olist_orders_dataset.csv",inferSchema=True, header=True)

df21.printSchema()
df22.printSchema()

df221=df22.withColumn('order_approved_at',to_date(df22.order_approved_at, 'yyyy-MM-dd HH:mm:ss'))
df222=df221.select(col("order_id"),col('order_status'),date_format(col("order_approved_at"), "dd-MM-yyyy")
.alias("order_approved"))
df222.show()

df61 = spark.read.csv("/content/olist_customers_dataset.csv",inferSchema=True, header=True)
df62 = spark.read.csv("/content/olist_geolocation_dataset.csv",inferSchema=True, header=True)

df61.printSchema()
df61.show(5)
df62.printSchema()
df62.show(5)

df61.createOrReplaceTempView("Customers")

df63=spark.sql("SELECT customer_city, COUNT(customer_id) as customer_count FROM Customers GROUP BY customer_city")
df63.show()

df22.createOrReplaceTempView("Orders")

df81=spark.sql("SELECT customer_id, COUNT(order_id) as order_count FROM Orders GROUP BY customer_id")
df82=df81.orderBy(desc("order_count")).show(1)

df83=spark.sql("SELECT seller_id, COUNT(order_id) as sales_count FROM OrderItems GROUP BY seller_id")
df84=df83.orderBy(desc("sales_count")).show(1)

df10=df61.join(df22, df61['customer_id'] == df22['customer_id'], how='inner').select(col('order_id'),col('customer_city'))
df10.show(5)

df10.createOrReplaceTempView("OrdersInCity")
df101=spark.sql("SELECT customer_city, COUNT(order_id) as orders_count FROM OrdersInCity GROUP BY customer_city")
df101.show()

df1.createOrReplaceTempView("Products")

df111 = spark.read.csv("/content/olist_order_reviews_dataset.csv",inferSchema=True, header=True)
df111.createOrReplaceTempView("Reviews")

df112=df1.join(df2, df1['product_id'] == df2['product_id'], how='inner').select(col('product_category_name'),
                                                                                col('order_id'))
df113=df111.join(df112, df111['order_id'] == df112['order_id'], how='inner').select(col('review_id'),
                                                                                col('product_category_name'))
df113.createOrReplaceTempView("MaxReviews")
df114=spark.sql("SELECT product_category_name, COUNT(review_id) as Maximum_reviewed_product FROM MaxReviews GROUP BY product_category_name")
df115=df114.orderBy(desc("Maximum_reviewed_product")).show(1)

df121=df1.join(df2, df1['product_id'] == df2['product_id'], how='inner').select(col('product_category_name'),
                                                                                col('price'))
df121.createOrReplaceTempView("MinMax")
df122=spark.sql("SELECT product_category_name, price as Minimum_priced_product FROM MinMax ORDER BY price").show(1)
df123=spark.sql("SELECT product_category_name, price as Maximum_priced_product FROM MinMax ORDER BY price DESC").show(1)